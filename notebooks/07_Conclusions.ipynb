{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # **Máster in Data Science - Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Frida Ibarra y Gema Romero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Analysis - Loan Default Prediction Model\n",
    "\n",
    "---\n",
    "\n",
    "**Project Objective**\n",
    "\n",
    "This project aims to develop a robust predictive model for identifying customers at high risk of default in the context of loan granting. The analysis is structured in several critical phases, each contributing to the ultimate goal of reducing financial risk for the lending institution. The process starts with an Exploratory Data Analysis (EDA), which provides an overview of the dataset’s characteristics and identifies variables that significantly impact loan default, as well as those that do not offer predictive value.\n",
    "\n",
    "---\n",
    "\n",
    "**Exploratory Data Analysis (EDA)**\n",
    "\n",
    "During the EDA, key patterns were observed:\n",
    "\n",
    "- Extreme Class Imbalance: One major challenge was the class imbalance in the dataset.\n",
    "  - The original dataset contains 246,008 rows.\n",
    "  - Majority class (customers who repay): approximately 95% of cases  \n",
    "  - Minority class (defaults): only approximately 5% of cases\n",
    "\n",
    "To address this imbalance, resampling techniques were employed, such as:\n",
    "- SMOTE (Oversampling) for the minority class  \n",
    "- Undersampling for the majority class  \n",
    "\n",
    "These techniques helped create a more balanced dataset, which improved the model's ability to predict loan defaults.\n",
    "\n",
    "---\n",
    "\n",
    "**Model Preparation and Development**\n",
    "\n",
    "In the model preparation phase:\n",
    "\n",
    "- Resampling techniques were crucial to balancing the dataset and ensuring better representation of both classes.\n",
    "- Different algorithms were tested, but the focus was on XGBoost, known for its effectiveness in handling large datasets and imbalanced classification problems.\n",
    "- The initial model showed promising results but tended to overclassify the majority class, resulting in a high false-negative rate, which is a critical issue in loan prediction.\n",
    "\n",
    "Key Evaluation Metrics Used:  \n",
    "- Accuracy  \n",
    "- Recall (especially important for minimizing false negatives)  \n",
    "- F2-Score (focuses on minimizing false negatives)\n",
    "\n",
    "By adjusting the decision threshold from 0.5 to 0.63, significant improvements were achieved, notably increasing recall for defaults from 0.72 to 0.80, while maintaining relatively stable precision.\n",
    "\n",
    "---\n",
    "\n",
    "**Detailed Evaluation Phase**\n",
    "\n",
    "The model's performance was evaluated using tools and metrics such as the confusion matrix, ROC curves, and Precision-Recall curves. These tools provided a comprehensive view of the model's behavior across different threshold values.\n",
    "\n",
    "- The confusion matrix highlighted errors in classifying defaults.\n",
    "- A cost matrix was implemented to quantify the economic impact of prediction errors. This analysis showed that false negatives (undetected defaults) have a higher cost than false positives (incorrectly labeled repayments).\n",
    "  \n",
    "By incorporating the cost matrix, the model prioritized reducing false negatives, with an estimated cost of $500 per undetected default.\n",
    "\n",
    "---\n",
    "\n",
    "**Further Optimization and Adjustments**\n",
    "\n",
    "Model optimization continued with deeper parameter analysis of the XGBoost model. Various hyperparameters were tested, including:\n",
    "\n",
    "- Learning Rate  \n",
    "- Max Depth  \n",
    "- n_estimators  \n",
    "- Regularization (lambda)  \n",
    "\n",
    "A key change was reducing the number of trees from 1000 to 300, which helped avoid overfitting while maintaining predictive accuracy. This optimization improved the F2-Score from 0.73 to 0.78.\n",
    "\n",
    "Additionally, a detailed feature analysis identified areas that could be further refined. There was consideration for incorporating new variables, although this will require further investigation.\n",
    "\n",
    "---\n",
    "\n",
    "**Importance of Model Interpretability with SHAP**\n",
    "\n",
    "A crucial part of the analysis involved interpreting the model's predictions using SHAP (SHapley Additive exPlanations) values. SHAP analysis revealed the most relevant features driving the model's predictions. Key influential variables included:\n",
    "\n",
    "- External sources of information (EXT_SOURCE_3, EXT_SOURCE_2, EXT_SOURCE_1), which captured significant credit risk factors.\n",
    "- Other relevant features included the credit request history (AMT_REQ_CREDIT_BUREAU_YEAR), employment characteristics (OCCUPATION_TYPE_MEAN), and educational background (NAME_EDUCATION_TYPE_ORDINAL).\n",
    "\n",
    "The SHAP summary plot showed that while primary features accounted for a significant portion of predictive accuracy, other features like FLAG_PHONE and temporal factors (WEEKDAY_APPR_PROCESS_START_ORDINAL) also contributed. The cumulative impact of these remaining features highlighted the multidimensional nature of the model.\n",
    "\n",
    "SHAP not only improved model interpretability but also enabled better communication with stakeholders. Decision-makers gained more confidence in the system’s predictions by understanding which variables were driving outcomes.\n",
    "\n",
    "---\n",
    "\n",
    "**Final Conclusion**\n",
    "\n",
    "In summary, a robust predictive model capable of accurately predicting loan defaults has been developed. This model incorporated resampling techniques, decision threshold adjustments, and thorough performance evaluations.\n",
    "\n",
    "While the goal of minimizing false negatives and accurately detecting defaults is being met, optimization remains an ongoing process. Integrating interpretability techniques like SHAP has further enhanced the model's performance.\n",
    "\n",
    "With SHAP analysis, the project achieved greater transparency and fairness in decision-making, which is crucial in financial applications. The cost matrix and ideal threshold matrix adjustments ensured optimal performance and financial outcomes, highlighting the importance of minimizing false negatives in practical loan prediction scenarios.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
